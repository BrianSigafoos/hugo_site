---
date: 2018-10-15T05:49:44-07:00
slug: postgres
title: Postgres tips
summary: A quick reference for working with PostgreSQL databases
---

### Total size

Get an estimate of the number of rows for an enormous table called "events".

```sql
SELECT reltuples::bigint AS rows_estimate FROM pg_class WHERE relname="events";
```

Or get a table of a database's largest relations and their total size in bytes,
total size pretty, and rows estimate.

```sql
SELECT
    nspname || '.' || relname AS "relation",
    pg_total_relation_size(C.oid) AS "total_size_bytes",
    pg_size_pretty(pg_total_relation_size(C.oid)) AS "total_size_pretty",
    reltuples::BIGINT AS "rows_estimate"
  FROM pg_class C
  LEFT JOIN pg_namespace N ON (N.oid = C.relnamespace)
  WHERE nspname NOT IN ('pg_catalog', 'information_schema')
    AND C.relkind <> 'i'
    AND nspname !~ '^pg_toast'
  ORDER BY pg_total_relation_size(C.oid) DESC
  LIMIT 200;
```

### pg_dump

```bash
cat .../<your-app>/.../database.yml
DB_HOST=<from database.yml>
DB_NAME=<from database.yml>
DB_USER=<from database.yml>
DB_DUMP_FILE=db.dump
# -Fc format custom, -v verbose
time (pg_dump -Fc -v -U $DB_USER -h $DB_HOST -d $DB_NAME -f $DB_DUMP_FILE)
```

```bash
SERVER_USER=<ie deploy>
SERVER_IP=<ie 1.2.3.4 >
DB_NAME=<ie database_prod>
REMOTE_DB_DUMP_FILE=db.dump
DATE=$(date +"%Y%m%d%H%M")
LOCAL_DB_DUMP=$HOME/.../$DB_NAME\-$DATE.dump

echo Fetching production database dump
scp $SERVER_USER@$SERVER_IP:$REMOTE_DB_DUMP_FILE $LOCAL_DB_DUMP
```

### pg_restore

Simple pg_restore for local development

```bash
cat .../<your-app>/.../database.yml
DB_NAME=<from database.yml>
DB_DUMP_FILE=db.dump

# -Fc --format=custom, -v --verbose
# -c --clean (clean/drop database objects before recreating them!)
time (pg_restore -Fc -v -c -d $DB_NAME $DB_DUMP_FILE)
```

More realistic scenario on production or staging server, using a `pg_restore.list`
option with `-L pg_restore.list`

```bash
DB_HOST=<from database.yml>
DB_NAME=<from database.yml>
DB_USER=<from database.yml>
DB_DUMP_FILE=db.dump
PG_RESTORE_LIST=pg_restore.list

pg_restore -l db.dump | grep -Fv -e 'COMMENT - EXTENSION' -e 'master' -e 'rdsadmin' > $PG_RESTORE_LIST
# -Fc --format=custom, -v --verbose, -O --no-owner, -1 --single-transaction
# -e --exit-on-error
time (pg_restore -Fc -v -O -1 -e -h $DB_HOST -d $DB_NAME -U $DB_USER -L $PG_RESTORE_LIST $DB_DUMP_FILE)
```

#### Restore specific table(s)

```bash
DB_HOST=<from database.yml>
DB_NAME=<from database.yml>
DB_USER=<from database.yml>
DB_DUMP_FILE=db.dump
DB_TABLE1=<ie users>
DB_TABLE2=<ie accounts>

# -Fc --format=custom, -v --verbose, -a --data-only, -1 --single-transaction
# -e --exit-on-error, -t --table (as many as needed)
time (pg_restore -Fc -v -a -1 -e -h $DB_HOST -d $DB_NAME -U $DB_USER -t $DB_TABLE1 -t $DB_TABLE2 $DB_DUMP_FILE)
```

### EXPLAIN

Add `EXPLAIN` before a query to get its execution plan.
Example: `EXPLAIN SELECT * FROM users WHERE id = 42;`

Add `EXPLAIN ANALYZE` for the statement to be actually executed, not only
planned. This is fine for `SELECT`. But, since the query is executed, be careful
with `INSERT, UPDATE, DELETE, CREATE TABLE AS`. Wrap those with a `BEGIN`
and `ROLLBACK`:

```sql
BEGIN;
EXPLAIN ANALYZE ...;
ROLLBACK;
```
